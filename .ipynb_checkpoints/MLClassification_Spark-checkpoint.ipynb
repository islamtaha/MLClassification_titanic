{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.appName(\"sparkml\").master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sparkSession.read.csv(\"titanic/train.csv\", header=True, inferSchema=True).repartition(60)\n",
    "test = sparkSession.read.csv(\"titanic/test.csv\", header=True, inferSchema=True).repartition(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------------+--------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|           Ticket|    Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------------+--------+-----+--------+\n",
      "|        421|       0|     3|Gheorgheff, Mr. S...|  male|null|    0|    0|           349254|  7.8958| null|       C|\n",
      "|        284|       1|     3|Dorking, Mr. Edwa...|  male|19.0|    0|    0|       A/5. 10482|    8.05| null|       S|\n",
      "|        558|       0|     1| Robbins, Mr. Victor|  male|null|    0|    0|         PC 17757| 227.525| null|       C|\n",
      "|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|           347064|    7.75| null|       S|\n",
      "|        327|       0|     3|Nysveen, Mr. Joha...|  male|61.0|    0|    0|           345364|  6.2375| null|       S|\n",
      "|        183|       0|     3|Asplund, Master. ...|  male| 9.0|    4|    2|           347077| 31.3875| null|       S|\n",
      "|        741|       1|     1|Hawksford, Mr. Wa...|  male|null|    0|    0|            16988|    30.0|  D45|       S|\n",
      "|        244|       0|     3|Maenpaa, Mr. Matt...|  male|22.0|    0|    0|STON/O 2. 3101275|   7.125| null|       S|\n",
      "|        242|       1|     3|\"Murphy, Miss. Ka...|female|null|    1|    0|           367230|    15.5| null|       Q|\n",
      "|        131|       0|     3|Drazenoic, Mr. Jozef|  male|33.0|    0|    0|           349241|  7.8958| null|       C|\n",
      "|        166|       1|     3|\"Goldsmith, Maste...|  male| 9.0|    0|    2|           363291|  20.525| null|       S|\n",
      "|        122|       0|     3|Moore, Mr. Leonar...|  male|null|    0|    0|        A4. 54510|    8.05| null|       S|\n",
      "|        447|       1|     2|Mellinger, Miss. ...|female|13.0|    0|    1|           250644|    19.5| null|       S|\n",
      "|        437|       0|     3|\"Ford, Miss. Dool...|female|21.0|    2|    2|       W./C. 6608|  34.375| null|       S|\n",
      "|        770|       0|     3|Gronnestad, Mr. D...|  male|32.0|    0|    0|             8471|  8.3625| null|       S|\n",
      "|        814|       0|     3|Andersson, Miss. ...|female| 6.0|    4|    2|           347082|  31.275| null|       S|\n",
      "|        857|       1|     1|Wick, Mrs. George...|female|45.0|    1|    1|            36928|164.8667| null|       S|\n",
      "|        699|       0|     1|Thayer, Mr. John ...|  male|49.0|    1|    1|            17421|110.8833|  C68|       C|\n",
      "|        416|       0|     3|Meek, Mrs. Thomas...|female|null|    0|    0|           343095|    8.05| null|       S|\n",
      "|        794|       0|     1|Hoyt, Mr. William...|  male|null|    0|    0|         PC 17600| 30.6958| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-----------------+--------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+------------------+-------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|            Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+------------------+-------+-----+--------+\n",
      "|       1201|     3|Hansen, Mrs. Clau...|female|45.0|    1|    0|            350026|14.1083| null|       S|\n",
      "|       1301|     3|Peacock, Miss. Tr...|female| 3.0|    1|    1|SOTON/O.Q. 3101315| 13.775| null|       S|\n",
      "|       1155|     3|Klasen, Miss. Ger...|female| 1.0|    1|    1|            350405|12.1833| null|       S|\n",
      "|        937|     3|Peltomaki, Mr. Ni...|  male|25.0|    0|    0| STON/O 2. 3101291|  7.925| null|       S|\n",
      "|       1237|     3|Abelseth, Miss. K...|female|16.0|    0|    0|            348125|   7.65| null|       S|\n",
      "+-----------+------+--------------------+------+----+-----+-----+------------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "cat_cols=['Sex','Embarked']\n",
    "train.fillna( { 'Embarked':'S'} )\n",
    "test.fillna( { 'Embarked':'S'} )\n",
    "\n",
    "cat_cols_index={'Sex':'Sex_Index','Embarked':'Embarked_Index'}\n",
    "\n",
    "cat_indexers = [ StringIndexer(inputCol=col, outputCol=cat_cols_index[col])\n",
    "                 for col in cat_cols ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|  0|  0|    0|    0|     0|   0|  687|       0|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n",
      "+-----------+--------+------+--------------------+----+-----------------+-----+-----+----------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name| Sex|              Age|SibSp|Parch|    Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+----+-----------------+-----+-----+----------+-------+-----+--------+\n",
      "|        421|       0|     3|Gheorgheff, Mr. S...|male|29.69911764705882|    0|    0|    349254| 7.8958| null|       C|\n",
      "|        284|       1|     3|Dorking, Mr. Edwa...|male|             19.0|    0|    0|A/5. 10482|   8.05| null|       S|\n",
      "|        558|       0|     1| Robbins, Mr. Victor|male|29.69911764705882|    0|    0|  PC 17757|227.525| null|       C|\n",
      "|        407|       0|     3|Widegren, Mr. Car...|male|             51.0|    0|    0|    347064|   7.75| null|       S|\n",
      "|        794|       0|     1|Hoyt, Mr. William...|male|29.69911764705882|    0|    0|  PC 17600|30.6958| null|       C|\n",
      "+-----------+--------+------+--------------------+----+-----------------+-----+-----+----------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.sql.functions import col, avg\n",
    "from pyspark.sql.functions import isnan, when, count\n",
    "\n",
    "\n",
    "def fill_with_mean(df, include=set()): \n",
    "    stats = df.agg(*(\n",
    "        avg(c).alias(c) for c in df.columns if c in include\n",
    "    ))\n",
    "    return df.na.fill(stats.first().asDict())\n",
    "\n",
    "train = fill_with_mean(train, ['Age'])\n",
    "test =fill_with_mean(test, ['Age'])\n",
    "train = train.filter(train.Embarked.isNotNull())\n",
    "train.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in train.columns]).show()\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=[ \"Pclass\", \"Sex_Index\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked_Index\"], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol='Survived',featuresCol='scaledfeatures', numTrees=100,maxDepth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledfeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = train.randomSplit([0.8, 0.2], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[ *cat_indexers, vector_assembler, standardScaler, rf ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(7, {0: 0.1302, 1: 0.4036, 2: 0.1556, 3: 0.1645, 4: 0.0639, 5: 0.0398, 6: 0.0424})"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[4].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313486005089058"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"Survived\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.filter(test.Fare.isNotNull())\n",
    "\n",
    "pred = model.transform(test)\n",
    "pred = pred.select(['PassengerId', 'Pclass', \"Name\", \"Sex\", \"Age\", \"Ticket\",\"parch\", \"SibSp\", \"Fare\", \"Cabin\", \"Embarked\", \"prediction\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in pred.columns]).show()\n",
    "pred.write.csv(\"Output_Prediction_test_Spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(maxIter=100, regParam=0.003, elasticNetParam=0, labelCol='Survived',featuresCol='scaledfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(stages=[ *cat_indexers, vector_assembler, standardScaler, log ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pipeline2.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7846310432569974"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = model2.transform(testData)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"Survived\")\n",
    "accuracy = evaluator.evaluate(predictions2)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP =  MultilayerPerceptronClassifier(maxIter=1000, layers=[7, 7, 5, 3, 2], seed=1234, labelCol='Survived',featuresCol='scaledfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3 = Pipeline(stages=[ *cat_indexers, vector_assembler, standardScaler, MLP ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = pipeline3.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7769974554707378"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3 = model3.transform(testData)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"Survived\")\n",
    "accuracy = evaluator.evaluate(predictions3)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
